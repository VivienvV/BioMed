{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0d89f9e0db8ec9de1f8d63865caf38d0a2356b4fd2842209f8b827ee72a018b27",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "d89f9e0db8ec9de1f8d63865caf38d0a2356b4fd2842209f8b827ee72a018b27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.train import train_and_test, cross_validation\n",
    "from model.code.load_data import preprocess_data\n",
    "from model.code.models import NN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of features that will be used:  918\n",
      "Epoch [50/50], Loss: 0.0000, Accuracy: 100.0\n",
      "Completed training!\n",
      "\n",
      "25 correct of  30\n",
      "Accuracy of the network on the test Array sequences: 83.33333333333333 %\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "([41.42857142857143,\n",
       "  78.57142857142857,\n",
       "  97.14285714285714,\n",
       "  97.14285714285714,\n",
       "  98.57142857142857,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0,\n",
       "  100.0],\n",
       " [tensor(1.0783, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.8390, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.3078, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0921, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0373, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0140, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0043, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0035, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0024, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0019, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0015, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0011, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0010, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0008, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0007, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0006, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0005, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0004, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0003, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0002, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(0.0001, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(9.3960e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(8.9855e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(8.1795e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(7.6782e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(7.2545e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(6.7790e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(6.3101e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.9747e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.6576e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.3037e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(5.0496e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(4.7358e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(4.5322e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(4.2683e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(3.9930e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(3.8439e-05, device='cuda:0', grad_fn=<DivBackward0>),\n",
       "  tensor(3.6511e-05, device='cuda:0', grad_fn=<DivBackward0>)],\n",
       " 83.33333333333333)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Model params\n",
    "parser.add_argument('--model', type=str, default='NN',\n",
    "                help='Which model to use for training: NN or LSTM')\n",
    "parser.add_argument('--num_features', type=int, default=2834,\n",
    "                help='Length of an input sequence/ amount of features each sample contains')\n",
    "parser.add_argument('--input_size', type=int, default=1,\n",
    "                help='Size of an input sequence')\n",
    "parser.add_argument('--LSTM_hidden_size', type=int, default=128,\n",
    "                help='Number of units in each LSTM layer')\n",
    "parser.add_argument('--LSTM_num_layers', type=int, default=2,\n",
    "                help='Number of hidden layers in the LSTM')\n",
    "parser.add_argument('--NN_hidden', type=list, default=[128,128,128],\n",
    "                help='List of which the length is the number of hidden layers and the values are the layer sizes in the NN')\n",
    "parser.add_argument('--num_classes', type=int, default=3,\n",
    "                help='Number of classes the model needs to be able to predict')\n",
    "\n",
    "# Training params\n",
    "parser.add_argument('--batch_size', type=int, default=7,\n",
    "                help='Number of examples to process in a batch')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                help='Learning rate')\n",
    "parser.add_argument('--num_epochs', type=int, default=50,\n",
    "                help='Amount of epochs used in training')\n",
    "parser.add_argument('--test_size', type=float, default=0.3,\n",
    "                help='Amount of data to use for testing (leave zero to use all data for training')\n",
    "parser.add_argument('--device', type=str, default='cuda',\n",
    "                help='Device to use (cpu or gpu)')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the data innto PyTorch\n",
    "train_call = pd.read_csv('full_data.csv', delimiter=',' )\n",
    "train_clin = pd.read_csv('Train_clinical.txt', delimiter='\\t' )\n",
    "train_arr, labels, new_df = preprocess_data(train_call, train_clin)\n",
    "\n",
    "args.num_features = train_arr.shape[1]\n",
    "print(\"Number of features that will be used: \", args.num_features)\n",
    "if args.model == 'NN':\n",
    "    model = NN(args).to(args.device)\n",
    "elif args.model == 'LSTM':\n",
    "    model = LSTM(args).to(args.device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_arr, labels, test_size=args.test_size)\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                    batch_size=args.batch_size,\n",
    "                                    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    shuffle=False)\n",
    "\n",
    "train_and_test(args, model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(918, 2)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     feature_no  feature_importance  \\\n",
       "702      2184.0            0.330739   \n",
       "768      2379.0            0.106000   \n",
       "66        230.0            0.101475   \n",
       "278       855.0            0.100935   \n",
       "719      2213.0            0.094339   \n",
       "..          ...                 ...   \n",
       "1          25.0            0.003993   \n",
       "173       554.0            0.003124   \n",
       "814      2537.0            0.002973   \n",
       "860      2671.0            0.002570   \n",
       "902      2772.0            0.002531   \n",
       "\n",
       "                                              gene_ids  \n",
       "702  ['ENSG00000113492', 'ENSG00000064999', 'ENSG00...  \n",
       "768  ['ENSG00000142892', 'ENSG00000176204', 'ENSG00...  \n",
       "66                                 ['ENSG00000118200']  \n",
       "278             ['ENSG00000113658', 'ENSG00000123453']  \n",
       "719  ['ENSG00000117013', 'ENSG00000064042', 'ENSG00...  \n",
       "..                                                 ...  \n",
       "1    ['ENSG00000041988', 'ENSG00000146576', 'ENSG00...  \n",
       "173  ['ENSG00000162620', 'ENSG00000188687', 'ENSG00...  \n",
       "814  ['ENSG00000215114', 'ENSG00000139734', 'ENSG00...  \n",
       "860  ['ENSG00000133216', 'ENSG00000173535', 'ENSG00...  \n",
       "902  ['ENSG00000144619', 'ENSG00000125386', 'ENSG00...  \n",
       "\n",
       "[918 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature_no</th>\n      <th>feature_importance</th>\n      <th>gene_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>702</th>\n      <td>2184.0</td>\n      <td>0.330739</td>\n      <td>['ENSG00000113492', 'ENSG00000064999', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>2379.0</td>\n      <td>0.106000</td>\n      <td>['ENSG00000142892', 'ENSG00000176204', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>66</th>\n      <td>230.0</td>\n      <td>0.101475</td>\n      <td>['ENSG00000118200']</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>855.0</td>\n      <td>0.100935</td>\n      <td>['ENSG00000113658', 'ENSG00000123453']</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>2213.0</td>\n      <td>0.094339</td>\n      <td>['ENSG00000117013', 'ENSG00000064042', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25.0</td>\n      <td>0.003993</td>\n      <td>['ENSG00000041988', 'ENSG00000146576', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>173</th>\n      <td>554.0</td>\n      <td>0.003124</td>\n      <td>['ENSG00000162620', 'ENSG00000188687', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>814</th>\n      <td>2537.0</td>\n      <td>0.002973</td>\n      <td>['ENSG00000215114', 'ENSG00000139734', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>860</th>\n      <td>2671.0</td>\n      <td>0.002570</td>\n      <td>['ENSG00000133216', 'ENSG00000173535', 'ENSG00...</td>\n    </tr>\n    <tr>\n      <th>902</th>\n      <td>2772.0</td>\n      <td>0.002531</td>\n      <td>['ENSG00000144619', 'ENSG00000125386', 'ENSG00...</td>\n    </tr>\n  </tbody>\n</table>\n<p>918 rows × 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# cross_validation(args, model, train_arr, labels)\n",
    "# batch = next(iter(train_loader))\n",
    "# batch = batch\n",
    "# data, _ = batch\n",
    "features = (new_df[\"ID_no\"]).tolist()\n",
    "gfeatures = (new_df[\"Gene_IDs\"]).tolist()\n",
    "# print(features)\n",
    "# print(len(features))\n",
    "# f = [x for x in features]\n",
    "# # df[\"fruit\"].astype(\"|S\")\n",
    "# print(len(features))\n",
    "# f = []\n",
    "sm = torch.load(\"model/NN.pth\").to(args.device)\n",
    "# dataset =  TensorDataset(torch.from_numpy(train_arr), torch.from_numpy(labels))\n",
    "X_full = np.vstack((X_train, X_test))\n",
    "e = shap.DeepExplainer(sm, torch.from_numpy(X_train).to(args.device))\n",
    "shap_values = e.shap_values(torch.from_numpy(X_full).to(args.device))\n",
    "\n",
    "\n",
    "class1 = shap_values[0]\n",
    "class2 = shap_values[1]\n",
    "class3 = shap_values[2]\n",
    "\n",
    "\n",
    "# shap.summary_plot(shap_values, features=torch.from_numpy(X_train).to(args.device), feature_names = features, show=False)\n",
    "# plt.savefig(\"summary_plot.png\")\n",
    "\n",
    "m = (np.mean(np.abs(shap_values), axis=0))\n",
    "# print(m.shape)\n",
    "mm = np.mean(m, axis=0)\n",
    "# print(mm.shape)\n",
    "new = np.c_[features, mm ]   \n",
    "print(new.shape)\n",
    "df = pd.DataFrame(new, columns=['feature_no', 'feature_importance'])\n",
    "# df = pd.DataFrame({\n",
    "#     \"mean_0\": np.mean(np.abs(class1), axis=0), \n",
    "#     \"std_0\": np.std(np.abs(class1), axis=0),\n",
    "#     \"id\":features\n",
    "# }, index=[2])\n",
    "\n",
    "# df.columns = ['feature_importance']\n",
    "# df = df.rename(index={0: \"feature_no\", 1: \"feature_importance\"})\n",
    "# df.head()\n",
    "# # print(df)\n",
    "# df.to_csv('final.csv')\n",
    "df['gene_ids'] = np.array(gfeatures)    \n",
    "# print(df)\n",
    "df = df.sort_values(by=['feature_importance'], ascending=False)\n",
    "df = df.astype({'feature_no': 'int32'})\n",
    "df = df.reset_index(drop=True)\n",
    "df\n",
    "# df.to_csv('final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}