{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0d89f9e0db8ec9de1f8d63865caf38d0a2356b4fd2842209f8b827ee72a018b27",
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "d89f9e0db8ec9de1f8d63865caf38d0a2356b4fd2842209f8b827ee72a018b27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model.code'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4a6a3e622d3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_and_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/BioMed/model/train.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model.code'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.train import train_and_test, cross_validation\n",
    "from model.code.load_data import preprocess_data\n",
    "from model.code.models import NN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Model params\n",
    "parser.add_argument('--model', type=str, default='NN',\n",
    "                help='Which model to use for training: NN or LSTM')\n",
    "parser.add_argument('--num_features', type=int, default=2834,\n",
    "                help='Length of an input sequence/ amount of features each sample contains')\n",
    "parser.add_argument('--input_size', type=int, default=1,\n",
    "                help='Size of an input sequence')\n",
    "parser.add_argument('--LSTM_hidden_size', type=int, default=128,\n",
    "                help='Number of units in each LSTM layer')\n",
    "parser.add_argument('--LSTM_num_layers', type=int, default=2,\n",
    "                help='Number of hidden layers in the LSTM')\n",
    "parser.add_argument('--NN_hidden', type=list, default=[128,128,128],\n",
    "                help='List of which the length is the number of hidden layers and the values are the layer sizes in the NN')\n",
    "parser.add_argument('--num_classes', type=int, default=3,\n",
    "                help='Number of classes the model needs to be able to predict')\n",
    "\n",
    "# Training params\n",
    "parser.add_argument('--batch_size', type=int, default=7,\n",
    "                help='Number of examples to process in a batch')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                help='Learning rate')\n",
    "parser.add_argument('--num_epochs', type=int, default=50,\n",
    "                help='Amount of epochs used in training')\n",
    "parser.add_argument('--test_size', type=float, default=0.3,\n",
    "                help='Amount of data to use for testing (leave zero to use all data for training')\n",
    "parser.add_argument('--device', type=str, default='cuda',\n",
    "                help='Device to use (cpu or gpu)')\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# Load the data innto PyTorch\n",
    "train_call = pd.read_csv('full_data.csv', delimiter=',' )\n",
    "train_clin = pd.read_csv('Train_clinical.txt', delimiter='\\t' )\n",
    "train_arr, labels, new_df = preprocess_data(train_call, train_clin)\n",
    "\n",
    "args.num_features = train_arr.shape[1]\n",
    "print(\"Number of features that will be used: \", args.num_features)\n",
    "if args.model == 'NN':\n",
    "    model = NN(args).to(args.device)\n",
    "elif args.model == 'LSTM':\n",
    "    model = LSTM(args).to(args.device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_arr, labels, test_size=args.test_size)\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "test_data = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, \n",
    "                                    batch_size=args.batch_size,\n",
    "                                    shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, \n",
    "                                    batch_size=args.batch_size, \n",
    "                                    shuffle=False)\n",
    "\n",
    "train_and_test(args, model, train_loader, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'new_df' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4100439a2b25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# batch = batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# data, _ = batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ID_no\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Gene_IDs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_df' is not defined"
     ]
    }
   ],
   "source": [
    "# cross_validation(args, model, train_arr, labels)\n",
    "# batch = next(iter(train_loader))\n",
    "# batch = batch\n",
    "# data, _ = batch\n",
    "features = (new_df[\"ID_no\"]).tolist()\n",
    "gfeatures = (new_df[\"Gene_IDs\"]).tolist()\n",
    "\n",
    "sm = torch.load(\"model/{}.pth\".format(args.model)).to(args.device)\n",
    "X_full = np.vstack((X_train, X_test))\n",
    "e = shap.DeepExplainer(sm, torch.from_numpy(X_train).to(args.device))\n",
    "shap_values = e.shap_values(torch.from_numpy(X_full).to(args.device))\n",
    "\n",
    "\n",
    "class1 = shap_values[0]\n",
    "class2 = shap_values[1]\n",
    "class3 = shap_values[2]\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values, features=torch.from_numpy(X_train).to(args.device), feature_names = features, show=False)\n",
    "plt.savefig(\"summary_plot.png\")\n",
    "\n",
    "m = (np.mean(np.abs(shap_values), axis=0))\n",
    "mm = np.mean(m, axis=0)\n",
    "new = np.c_[features, mm ]   \n",
    "df = pd.DataFrame(new, columns=['feature_no', 'feature_importance'])\n",
    "df['gene_ids'] = np.array(gfeatures)    \n",
    "df = df.sort_values(by=['feature_importance'], ascending=False)\n",
    "df = df.astype({'feature_no': 'int32'})\n",
    "df = df.reset_index(drop=True)\n",
    "df\n",
    "# df.to_csv('final.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}